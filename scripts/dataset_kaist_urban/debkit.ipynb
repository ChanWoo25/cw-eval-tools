{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complex Urban Dataset\n",
    "- Complex Urban Dataset with Multi-level Sensors from Highly Diverse Urban Environments (IJRR 2019)\n",
    "- https://sites.google.com/view/complex-urban-dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from io import TextIOWrapper\n",
    "import sys\n",
    "import struct\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "import tarfile"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before extraction\n",
    "```bash\n",
    "dataset_kaist_urban/\n",
    "├── campus00\n",
    "│   ├── campus00_calibration.tar.gz\n",
    "│   ├── campus00_data.tar.gz\n",
    "│   ├── campus00_las.tar.gz\n",
    "│   └── campus00_pose.tar.gz\n",
    "├── urban00\n",
    "│   ├── urban00_calibration.tar.gz\n",
    "│   ├── urban00_data.tar.gz\n",
    "│   ├── urban00_las.tar.gz\n",
    "│   └── urban00_pose.tar.gz\n",
    "├── urban01\n",
    "├── urban02\n",
    "├── urban03\n",
    "└── urban04\n",
    "```\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tar(root: Path, tar_fn: Path):\n",
    "    with tarfile.open(tar_fn) as tar :\n",
    "        tar.extractall(path=root)\n",
    "\n",
    "def rotmat2quat(R):\n",
    "    rotation = Rotation.from_matrix(R)\n",
    "    quaternion = rotation.as_quat()\n",
    "    return quaternion\n",
    "\n",
    "def procPose(root: Path, seq: str):\n",
    "    old_pose_fn = root / seq / 'global_pose.csv'\n",
    "    new_pose_fn = root / seq / 'pose.txt'\n",
    "\n",
    "    f_old = open(old_pose_fn, 'r')\n",
    "    f_new = open(new_pose_fn, 'w')\n",
    "\n",
    "    while True:\n",
    "        line = f_old.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        rot = np.zeros((3, 3), dtype=float)\n",
    "        tra = np.zeros((3,), dtype=float)\n",
    "        words = line.split(',')\n",
    "        timestamp = float(words[0]) / 1e9\n",
    "        rot[0,0] = float(words[1])\n",
    "        rot[0,1] = float(words[2])\n",
    "        rot[0,2] = float(words[3])\n",
    "        tra[0]   = float(words[4])\n",
    "        rot[1,0] = float(words[5])\n",
    "        rot[1,1] = float(words[6])\n",
    "        rot[1,2] = float(words[7])\n",
    "        tra[1]   = float(words[8])\n",
    "        rot[2,0] = float(words[9])\n",
    "        rot[2,1] = float(words[10])\n",
    "        rot[2,2] = float(words[11])\n",
    "        tra[2]   = float(words[12])\n",
    "        quat = rotmat2quat(rot)\n",
    "        new_words = []\n",
    "        new_words.append(f'{timestamp:.6f}')\n",
    "        new_words.append(f'{tra[0]:.6f}')\n",
    "        new_words.append(f'{tra[1]:.6f}')\n",
    "        new_words.append(f'{tra[2]:.6f}')\n",
    "        new_words.append(f'{quat[0]:.6f}')\n",
    "        new_words.append(f'{quat[1]:.6f}')\n",
    "        new_words.append(f'{quat[2]:.6f}')\n",
    "        new_words.append(f'{quat[3]:.6f}')\n",
    "        new_line = ' '.join(new_words) + '\\n'\n",
    "        f_new.write(new_line)\n",
    "        # print(timestamp)\n",
    "        # print(f\"quat: [{quat[0]:.3f} {quat[1]:.3f} {quat[2]:.3f} {quat[3]:.3f}]\")\n",
    "        # print(f\"tran: [{tra[0]:.3f} {tra[1]:.3f} {tra[2]:.3f}]\")\n",
    "\n",
    "    f_old.close()\n",
    "    f_new.close()\n",
    "    print(f\"- done pose.txt\")\n",
    "\n",
    "def procCalib(root: Path, seq: str, old_name: str, new_name: str):\n",
    "    old_calib_fn = root / seq / 'calibration' / old_name\n",
    "    new_calib_fn = root / seq / 'calibration' / new_name\n",
    "\n",
    "    f_old = open(old_calib_fn, 'r')\n",
    "    f_new = open(new_calib_fn, 'w')\n",
    "    \n",
    "    lines = f_old.readlines()\n",
    "    R_words = lines[3][2:].strip().split(' ')\n",
    "    t_words = lines[4][2:].strip().split(' ')\n",
    "    rotmat = np.zeros((3, 3), dtype=float)\n",
    "    trans = np.zeros((3,), dtype=float)\n",
    "    rotmat[0,0] = float(R_words[0])\n",
    "    rotmat[0,1] = float(R_words[1])\n",
    "    rotmat[0,2] = float(R_words[2])\n",
    "    rotmat[1,0] = float(R_words[3])\n",
    "    rotmat[1,1] = float(R_words[4])\n",
    "    rotmat[1,2] = float(R_words[5])\n",
    "    rotmat[2,0] = float(R_words[6])\n",
    "    rotmat[2,1] = float(R_words[7])\n",
    "    rotmat[2,2] = float(R_words[8])\n",
    "    trans[0]   = float(t_words[0])\n",
    "    trans[1]   = float(t_words[1])\n",
    "    trans[2]   = float(t_words[2])\n",
    "    quat = rotmat2quat(rotmat)\n",
    "    new_words = []\n",
    "    new_words.append(f'{trans[0]:.6f}')\n",
    "    new_words.append(f'{trans[1]:.6f}')\n",
    "    new_words.append(f'{trans[2]:.6f}')\n",
    "    new_words.append(f'{quat[0]:.6f}')\n",
    "    new_words.append(f'{quat[1]:.6f}')\n",
    "    new_words.append(f'{quat[2]:.6f}')\n",
    "    new_words.append(f'{quat[3]:.6f}')\n",
    "    new_line = ' '.join(new_words) + '\\n'\n",
    "    \n",
    "    f_new.write(new_line)\n",
    "    print(new_line, end='')\n",
    "    \n",
    "    f_old.close()\n",
    "    f_new.close()\n",
    "    print(f\"- done {new_name}\")\n",
    "    \n",
    "def procLidarScans(root: Path, seq: str):\n",
    "    for pos in ['left', 'right']:\n",
    "        \n",
    "        old_data_fn = root / seq / 'sensor_data' / f'VLP_{pos}_stamp.csv'\n",
    "        new_data_fn = root / seq / f'lidar_{pos}_data.txt'\n",
    "        f_old_data = open(old_data_fn, 'r')\n",
    "        f_new_data = open(new_data_fn, 'w')\n",
    "        \n",
    "        old_lidar_dir = root / seq / 'sensor_data' / f'VLP_{pos}'\n",
    "        new_lidar_dir = root / seq / f'lidar_{pos}'\n",
    "        os.makedirs(new_lidar_dir, exist_ok=True)\n",
    "\n",
    "        idx = 0\n",
    "        while True:\n",
    "            line = f_old_data.readline().strip()\n",
    "            if not line: \n",
    "                break\n",
    "            timestamp = float(line) / 1e9\n",
    "            \n",
    "            old_lidar_path = old_lidar_dir / f\"{line}.bin\"\n",
    "            new_lidar_path = new_lidar_dir / f\"{idx:06d}.bin\"\n",
    "            if not old_lidar_path.exists():\n",
    "                print(f\"{old_lidar_path} doesn't exist!\")\n",
    "                continue\n",
    "            os.rename(\n",
    "                old_lidar_path,\n",
    "                new_lidar_path)\n",
    "            \n",
    "            new_line = f\"{timestamp:.6f} lidar_{pos}/{idx:06d}.bin\\n\"\n",
    "            f_new_data.write(new_line)\n",
    "            idx += 1\n",
    "            \n",
    "        f_old_data.close()\n",
    "        f_new_data.close()\n",
    "        print(f\"- {pos} lidar done\")\n",
    "        \n",
    "def procSequence(root: Path, seq: str):\n",
    "    calibration_fn = root / f'{seq}_calibration.tar.gz'\n",
    "    data_fn = root / f'{seq}_data.tar.gz'\n",
    "    las_fn = root / f'{seq}_las.tar.gz'\n",
    "    pose_fn = root / f'{seq}_pose.tar.gz'\n",
    "    extract_tar(root, calibration_fn)\n",
    "    extract_tar(root, data_fn)\n",
    "    extract_tar(root, las_fn)\n",
    "    extract_tar(root, pose_fn)\n",
    "    print(f\"- done extraction\")\n",
    "    \n",
    "    procCalib(root, seq, 'Vehicle2LeftVLP.txt', 'Base2LeftLiDAR.txt')\n",
    "    procCalib(root, seq, 'Vehicle2RightVLP.txt', 'Base2RightLiDAR.txt')\n",
    "    procCalib(root, seq, 'Vehicle2IMU.txt', 'Base2Imu.txt')\n",
    "    \n",
    "    procLidarScans(root, seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process urban00 starts ...\n",
      "- done extraction\n",
      "-0.311890 0.394734 1.946610 -0.349085 0.152303 0.856673 0.347930\n",
      "- done Base2LeftLiDAR.txt\n",
      "-0.306052 -0.417145 1.952230 -0.349759 -0.146389 0.855857 -0.351777\n",
      "- done Base2RightLiDAR.txt\n",
      "-0.070000 0.000000 1.700000 0.000000 0.000000 0.000000 1.000000\n",
      "- done Base2Imu.txt\n",
      "- left lidar done\n",
      "- right lidar done\n",
      "Process urban01 starts ...\n",
      "- done extraction\n",
      "-0.311890 0.394734 1.946610 -0.349085 0.152303 0.856673 0.347930\n",
      "- done Base2LeftLiDAR.txt\n",
      "-0.306052 -0.417145 1.952230 -0.349759 -0.146389 0.855857 -0.351777\n",
      "- done Base2RightLiDAR.txt\n",
      "-0.070000 0.000000 1.700000 0.000000 0.000000 0.000000 1.000000\n",
      "- done Base2Imu.txt\n",
      "- left lidar done\n",
      "- right lidar done\n",
      "Process urban02 starts ...\n",
      "- done extraction\n",
      "-0.311890 0.394734 1.946610 -0.349085 0.152303 0.856673 0.347930\n",
      "- done Base2LeftLiDAR.txt\n",
      "-0.306052 -0.417145 1.952230 -0.349759 -0.146389 0.855857 -0.351777\n",
      "- done Base2RightLiDAR.txt\n",
      "-0.070000 0.000000 1.700000 0.000000 0.000000 0.000000 1.000000\n",
      "- done Base2Imu.txt\n",
      "- left lidar done\n",
      "- right lidar done\n",
      "Process urban03 starts ...\n",
      "- done extraction\n",
      "-0.311890 0.394734 1.946610 -0.349085 0.152303 0.856673 0.347930\n",
      "- done Base2LeftLiDAR.txt\n",
      "-0.306052 -0.417145 1.952230 -0.349759 -0.146389 0.855857 -0.351777\n",
      "- done Base2RightLiDAR.txt\n",
      "-0.070000 0.000000 1.700000 0.000000 0.000000 0.000000 1.000000\n",
      "- done Base2Imu.txt\n",
      "- left lidar done\n",
      "/data/datasets/dataset_kaist_urban/urban03/sensor_data/VLP_right/1519145335358107000.bin doesn't exist!\n",
      "- right lidar done\n",
      "Process urban04 starts ...\n",
      "- done extraction\n",
      "-0.311890 0.394734 1.946610 -0.349085 0.152303 0.856673 0.347930\n",
      "- done Base2LeftLiDAR.txt\n",
      "-0.306052 -0.417145 1.952230 -0.349759 -0.146389 0.855857 -0.351777\n",
      "- done Base2RightLiDAR.txt\n",
      "-0.070000 0.000000 1.700000 0.000000 0.000000 0.000000 1.000000\n",
      "- done Base2Imu.txt\n",
      "- left lidar done\n",
      "/data/datasets/dataset_kaist_urban/urban04/sensor_data/VLP_right/1519154599984854000.bin doesn't exist!\n",
      "- right lidar done\n"
     ]
    }
   ],
   "source": [
    "ROOT = Path('/data/datasets/dataset_kaist_urban')\n",
    "SEQS = [\n",
    "    # 'campus00', \n",
    "    'urban00', \n",
    "    'urban01', \n",
    "    'urban02', \n",
    "    'urban03', \n",
    "    'urban04'] \n",
    "# SEQS2 = [\n",
    "#   'urban09', \n",
    "#   'urban10']\n",
    "for seq in SEQS:\n",
    "    print(f\"Process {seq} starts ...\")\n",
    "    procSequence(ROOT, seq)\n",
    "    \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After Extraction list below...\n",
    "```bash\n",
    "dataset_kaist_urban/\n",
    "└── campus00\n",
    "    ├── calibration\n",
    "    ├── global_pose.csv\n",
    "    ├── sensor_data\n",
    "    └── sick_pointcloud.las\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
