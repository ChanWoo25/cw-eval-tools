{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NCLT Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from io import TextIOWrapper\n",
    "import sys\n",
    "import struct\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "NCLT_ROOT = Path('/data/datasets/dataset_nclt')\n",
    "NCLT_SEQS = [\n",
    "    '2012-05-26', \n",
    "    '2012-08-20', \n",
    "    '2012-09-28',\n",
    "    '2013-04-05']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVelSyncPaths(seq_name):\n",
    "    paths = glob(str(NCLT_ROOT / seq_name / 'velodyne_sync/*.bin'))\n",
    "    paths.sort()\n",
    "    return paths"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vel_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "scan_paths = getVelSyncPaths('2012-05-26')\n",
    "print(len(scan_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(x_s, y_s, z_s):\n",
    "    scaling = 0.005 # 5 mm\n",
    "    offset = -100.0\n",
    "    x = x_s * scaling + offset\n",
    "    y = y_s * scaling + offset\n",
    "    z = z_s * scaling + offset\n",
    "    return x, y, z\n",
    "\n",
    "def readPoint(f_bin: TextIOWrapper):\n",
    "    buf = f_bin.read(2)\n",
    "    if len(buf) != 2: return False, []\n",
    "    x = struct.unpack('<H', buf)[0]\n",
    "    y = struct.unpack('<H', f_bin.read(2))[0]\n",
    "    z = struct.unpack('<H', f_bin.read(2))[0]\n",
    "    i = struct.unpack('B', f_bin.read(1))[0]\n",
    "    l = struct.unpack('B', f_bin.read(1))[0]\n",
    "    x, y, z = convert(x, y, z)\n",
    "    return True, [x, y, z, i]\n",
    "\n",
    "def readSingleBin(bin_path: Path):\n",
    "    print(bin_path)\n",
    "    f_bin = open(bin_path, mode=\"rb\") # encoding=\"ISO-8859-1\"\n",
    "    points = []\n",
    "    \n",
    "    while True:\n",
    "        success, point = readPoint(f_bin)\n",
    "        if success:\n",
    "            points.append(point)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    points = np.asarray(points)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(points[:, 0], points[:, 1], -points[:, 2], c=-points[:, 2], s=5, linewidths=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# readSingleBin(str(scan_paths[200]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rearrange LiDAR Scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lidar_data_fn:  /data/datasets/dataset_nclt/2012-08-20/lidar_data.txt\n",
      "old_lidar_dir:  /data/datasets/dataset_nclt/2012-08-20/velodyne_sync\n",
      "new_lidar_dir:  /data/datasets/dataset_nclt/2012-08-20/lidar\n",
      "lidar_data_fn:  /data/datasets/dataset_nclt/2012-09-28/lidar_data.txt\n",
      "old_lidar_dir:  /data/datasets/dataset_nclt/2012-09-28/velodyne_sync\n",
      "new_lidar_dir:  /data/datasets/dataset_nclt/2012-09-28/lidar\n",
      "lidar_data_fn:  /data/datasets/dataset_nclt/2013-04-05/lidar_data.txt\n",
      "old_lidar_dir:  /data/datasets/dataset_nclt/2013-04-05/velodyne_sync\n",
      "new_lidar_dir:  /data/datasets/dataset_nclt/2013-04-05/lidar\n"
     ]
    }
   ],
   "source": [
    "## Rename\n",
    "NCLT_ROOT = Path('/data/datasets/dataset_nclt')\n",
    "NCLT_SEQS = [\n",
    "    '2012-05-26', \n",
    "    '2012-08-20', \n",
    "    '2012-09-28',\n",
    "    '2013-04-05']\n",
    "\n",
    "def rearrage_lidar(root:Path, seq:str):\n",
    "    lidar_data_fn = root / seq / 'lidar_data.txt'\n",
    "    old_lidar_dir = root / seq / 'velodyne_sync'\n",
    "    new_lidar_dir = root / seq / 'lidar'\n",
    "    print(\"lidar_data_fn: \", lidar_data_fn)\n",
    "    print(\"old_lidar_dir: \", old_lidar_dir)\n",
    "    print(\"new_lidar_dir: \", new_lidar_dir)\n",
    "    \n",
    "    if lidar_data_fn.exists():\n",
    "        print(f\"Don't overwrite {lidar_data_fn}\")\n",
    "        return False\n",
    "    if not root.exists():\n",
    "        print(f\"{root} doesn't exist!\")\n",
    "        return False\n",
    "    if not old_lidar_dir.exists():\n",
    "        print(f\"{old_lidar_dir} doesn't exist!\")\n",
    "        return False\n",
    "        \n",
    "    os.makedirs(new_lidar_dir, exist_ok=True)\n",
    "    f_data = open(lidar_data_fn, 'w')\n",
    "    scan_paths = glob(f\"{old_lidar_dir}/*.bin\")\n",
    "    scan_paths.sort()\n",
    "    \n",
    "    timestamps = []\n",
    "    for scan_path in scan_paths:\n",
    "        timestamp = float(Path(scan_path).name.split('.')[0]) / 1e6\n",
    "        timestamps.append(timestamp)\n",
    "        if len(timestamps) >= 2:\n",
    "            if timestamps[-2] >= timestamps[-1]:\n",
    "                print(\"Time order is wrong!\")\n",
    "                return False\n",
    "    \n",
    "    assert (len(timestamps) == len(scan_paths))\n",
    "    \n",
    "    for index in range(len(timestamps)):\n",
    "        line = f\"{timestamps[index]:.6f} lidar/{index:06d}.bin\\n\"\n",
    "        old_scan_fn = scan_paths[index]\n",
    "        new_scan_fn = f\"{new_lidar_dir}/{index:06d}.bin\"\n",
    "        # print(old_scan_fn)\n",
    "        # print(new_scan_fn)\n",
    "        os.rename(old_scan_fn, new_scan_fn)\n",
    "        f_data.write(line)\n",
    "\n",
    "    f_data.close()\n",
    "    return True\n",
    "\n",
    "# success = rearrage_lidar(NCLT_ROOT, NCLT_SEQS[0])\n",
    "success = rearrage_lidar(NCLT_ROOT, NCLT_SEQS[1])\n",
    "success = rearrage_lidar(NCLT_ROOT, NCLT_SEQS[2])\n",
    "success = rearrage_lidar(NCLT_ROOT, NCLT_SEQS[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/datasets/dataset_nclt/2012-05-26/lidar/1338074755120693.bin\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data/datasets/dataset_nclt/2012-05-26/lidar/1338074755120693.bin'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m readSingleBin(\u001b[39mstr\u001b[39;49m(scan_paths[\u001b[39m200\u001b[39;49m]))\n",
      "Cell \u001b[0;32mIn[20], line 22\u001b[0m, in \u001b[0;36mreadSingleBin\u001b[0;34m(bin_path)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreadSingleBin\u001b[39m(bin_path: Path):\n\u001b[1;32m     21\u001b[0m     \u001b[39mprint\u001b[39m(bin_path)\n\u001b[0;32m---> 22\u001b[0m     f_bin \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(bin_path, mode\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39m# encoding=\"ISO-8859-1\"\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     points \u001b[39m=\u001b[39m []\n\u001b[1;32m     25\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/data/datasets/dataset_nclt/2012-05-26/lidar/1338074755120693.bin'"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
